{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f70796fb-7b0e-49eb-a4ee-801c4916e839",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset generation completed.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import os\n",
    "import tkinter as tk\n",
    "from tkinter import simpledialog\n",
    "\n",
    "# Initialize MediaPipe Hand module\n",
    "mp_hands = mp.solutions.hands\n",
    "hands = mp_hands.Hands(max_num_hands=1)\n",
    "mp_draw = mp.solutions.drawing_utils\n",
    "\n",
    "# Initialize the main window using Tkinter\n",
    "root = tk.Tk()\n",
    "root.withdraw()  # Hide the root window\n",
    "\n",
    "def get_hand_type(hand_landmarks, w):\n",
    "    \"\"\"Determine if the hand is left or right based on landmark positions.\"\"\"\n",
    "    wrist_x = hand_landmarks.landmark[mp_hands.HandLandmark.WRIST].x * w\n",
    "    hand_type = \"Right\" if wrist_x > w / 2 else \"Left\"\n",
    "    return hand_type\n",
    "\n",
    "def capture_images(sign, num_images=2800, delay=2):\n",
    "    # Create a directory for the sign if it doesn't exist\n",
    "    if not os.path.exists(sign):\n",
    "        os.makedirs(sign)\n",
    "\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    count = 0\n",
    "    capture_started = False\n",
    "\n",
    "    while count < num_images:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        results = hands.process(rgb_frame)\n",
    "\n",
    "        if results.multi_hand_landmarks:\n",
    "            for hand_landmarks in results.multi_hand_landmarks:\n",
    "                hand_type = get_hand_type(hand_landmarks, frame.shape[1])  # Determine hand type\n",
    "                frame_to_save = frame.copy()\n",
    "                h, w, c = frame.shape\n",
    "                x_min, y_min = w, h\n",
    "                x_max, y_max = 0, 0\n",
    "\n",
    "                for landmark in hand_landmarks.landmark:\n",
    "                    x, y = int(landmark.x * w), int(landmark.y * h)\n",
    "                    x_min, y_min = min(x_min, x), min(y_min, y)\n",
    "                    x_max, y_max = max(x_max, x), max(y_max, y)\n",
    "\n",
    "                padding = 10\n",
    "                x_min = max(x_min - padding, 0)\n",
    "                y_min = max(y_min - padding, 0)\n",
    "                x_max = min(x_max + padding, w)\n",
    "                y_max = min(y_max + padding, h)\n",
    "\n",
    "                # Draw a green rectangle around the detected hand\n",
    "                cv2.rectangle(frame, (x_min, y_min), (x_max, y_max), (0, 255, 0), 2)\n",
    "                mp_draw.draw_landmarks(frame, hand_landmarks, mp_hands.HAND_CONNECTIONS)\n",
    "\n",
    "                # Display the rectangle and prompt the user\n",
    "                if not capture_started:\n",
    "                    cv2.putText(frame, \"Place your hand within the green rectangle\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2, cv2.LINE_AA)\n",
    "                    cv2.putText(frame, \"Capturing will start in 3 seconds...\", (10, 70), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2, cv2.LINE_AA)\n",
    "                    cv2.imshow('Capturing Sign', frame)\n",
    "                    cv2.waitKey(3000)  # Wait for 3 seconds\n",
    "                    capture_started = True\n",
    "\n",
    "                # Capture the image after showing the rectangle\n",
    "                hand_roi = frame_to_save[y_min:y_max, x_min:x_max]\n",
    "\n",
    "                if hand_roi.size > 0:\n",
    "                    hand_roi_resized = cv2.resize(hand_roi, (128, 128))  # Resize to 128x128\n",
    "                    hand_roi_gray = cv2.cvtColor(hand_roi_resized, cv2.COLOR_BGR2GRAY)  # Convert to grayscale\n",
    "\n",
    "                    img_name = f\"{sign}/{count + 1}.jpg\"\n",
    "                    cv2.imwrite(img_name, hand_roi_gray)\n",
    "                    count += 1\n",
    "\n",
    "                    cv2.putText(frame, f\"Capturing {sign} - {count}/{num_images}\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2, cv2.LINE_AA)\n",
    "\n",
    "                if count >= num_images:\n",
    "                    break\n",
    "\n",
    "        cv2.imshow('Capturing Sign', frame)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "def capture_for_all_signs(signs, num_images=2800, delay=2):\n",
    "    for sign in signs:\n",
    "        capture_images(sign, num_images, delay)\n",
    "\n",
    "# Main loop to capture images based on the sign entered by the user\n",
    "while True:\n",
    "    sign = simpledialog.askstring(\"Input\", \"Enter the sign (A, B, etc.) or 'q' to quit:\")\n",
    "\n",
    "    if sign == 'q' or sign is None:\n",
    "        break\n",
    "\n",
    "    capture_images(sign)\n",
    "\n",
    "print(\"Dataset generation completed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "404c940b-9c67-40e4-864c-1a66708a6427",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b458babf-64dc-441e-bc1b-931732e5f683",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import os\n",
    "import tkinter as tk\n",
    "from tkinter import simpledialog\n",
    "import time\n",
    "\n",
    "# Initialize MediaPipe Hand module\n",
    "mp_hands = mp.solutions.hands\n",
    "hands = mp_hands.Hands(max_num_hands=1)\n",
    "mp_draw = mp.solutions.drawing_utils\n",
    "\n",
    "# Initialize the main window using Tkinter\n",
    "root = tk.Tk()\n",
    "root.withdraw()  # Hide the root window\n",
    "\n",
    "# Function to capture images for a given sign\n",
    "def capture_images(sign):\n",
    "    # Create a directory for the sign if it doesn't exist\n",
    "    if not os.path.exists(sign):\n",
    "        os.makedirs(sign)\n",
    "\n",
    "    # Start video capture\n",
    "    cap = cv2.VideoCapture(0)\n",
    "\n",
    "    # Set up variables\n",
    "    count = 0\n",
    "    capture_started = False\n",
    "\n",
    "    while count < 400:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Convert the image to RGB (MediaPipe works with RGB images)\n",
    "        rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # Process the frame and detect hands\n",
    "        results = hands.process(rgb_frame)\n",
    "\n",
    "        if results.multi_hand_landmarks:\n",
    "            for hand_landmarks in results.multi_hand_landmarks:\n",
    "                # Create a copy of the frame for saving purposes\n",
    "                frame_to_save = frame.copy()\n",
    "\n",
    "                # Get the bounding box around the hand\n",
    "                h, w, c = frame.shape\n",
    "                x_min, y_min = w, h\n",
    "                x_max, y_max = 0, 0\n",
    "\n",
    "                for landmark in hand_landmarks.landmark:\n",
    "                    x, y = int(landmark.x * w), int(landmark.y * h)\n",
    "                    x_min, y_min = min(x_min, x), min(y_min, y)\n",
    "                    x_max, y_max = max(x_max, x), max(y_max, y)\n",
    "\n",
    "                # Expand the bounding box slightly for better ROI\n",
    "                padding = 10\n",
    "                x_min = max(x_min - padding, 0)\n",
    "                y_min = max(y_min - padding, 0)\n",
    "                x_max = min(x_max + padding, w)\n",
    "                y_max = min(y_max + padding, h)\n",
    "\n",
    "                # Draw hand landmarks on the frame for real-time display\n",
    "                mp_draw.draw_landmarks(frame, hand_landmarks, mp_hands.HAND_CONNECTIONS)\n",
    "\n",
    "                # Extract the hand region as a separate image from the copy\n",
    "                hand_roi = frame_to_save[y_min:y_max, x_min:x_max]\n",
    "\n",
    "                if hand_roi.size > 0:\n",
    "                    if not capture_started:\n",
    "                        # Wait for 2 seconds before starting to capture\n",
    "                        time.sleep(2)\n",
    "                        capture_started = True\n",
    "\n",
    "                    # Resize the hand ROI to 128x128\n",
    "                    hand_roi_resized = cv2.resize(hand_roi, (256, 256))\n",
    "\n",
    "                    img_name = f\"{sign}/{count + 1}.jpg\"\n",
    "                    cv2.imwrite(img_name, hand_roi_resized)\n",
    "                    count += 1\n",
    "\n",
    "                    # Display the frame count on the frame\n",
    "                    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "                    cv2.putText(frame, f\"Capturing {sign} - {count}/400\", (10, 30), font, 1, (255, 0, 0), 2, cv2.LINE_AA)\n",
    "\n",
    "                # Break the loop after capturing 300 images\n",
    "                if count >= 400:\n",
    "                    break\n",
    "\n",
    "        # Display the frame with the landmarks\n",
    "        cv2.imshow('Capturing Sign', frame)\n",
    "\n",
    "        # Break the loop if 'q' is pressed\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# Main loop to capture images based on the sign entered by the user\n",
    "while True:\n",
    "    # Ask the user for the sign (e.g., A, B, etc.)\n",
    "    sign = simpledialog.askstring(\"Input\", \"Enter the sign (A, B, etc.) or 'q' to quit:\")\n",
    "\n",
    "    if sign == 'q' or sign is None:\n",
    "        break\n",
    "\n",
    "    capture_images(sign)\n",
    "\n",
    "print(\"Dataset generation completed.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
